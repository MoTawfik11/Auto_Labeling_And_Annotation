{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d8cd265",
   "metadata": {},
   "source": [
    "Check the GPU drivers and CUDA are available for better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdeef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139be368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU detected. Please check your driver/CUDA setup.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c41ab6",
   "metadata": {},
   "source": [
    "Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.17.0\n",
    "!pip install autodistill\n",
    "!pip install autodistill-grounded-sam\n",
    "!pip install autodistill-yolov8\n",
    "!pip install supervision==0.24.0\n",
    "!pip install scikit-learn\n",
    "!pip install roboflow\n",
    "!pip install opencv-python\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca1020",
   "metadata": {},
   "source": [
    "Training video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train video path (Multiple Video if needed)\n",
    "TRAIN_VIDEO_PATHS = [\"Train_Vid.mp4\"]\n",
    "\n",
    "# Interval for extracting every Nth frame from a video \n",
    "FRAME_STRIDE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a103723c",
   "metadata": {},
   "source": [
    "Folders names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d604196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save frames from video\n",
    "IMAGE_DIR_PATH = \"Images\"\n",
    "\n",
    "# Folder path to final dataset\n",
    "DATASET_DIR_PATH = \"Dataset\"\n",
    "\n",
    "# View samples variables\n",
    "SAMPLE_SIZE = 25\n",
    "SAMPLE_GRID_SIZE = (5, 5)\n",
    "SAMPLE_PLOT_SIZE = (15, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bad294",
   "metadata": {},
   "source": [
    "Cut the video to frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82536c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "for video_path in tqdm(TRAIN_VIDEO_PATHS):\n",
    "    video_path = Path(video_path)\n",
    "    video_name = video_path.stem\n",
    "    image_name_pattern = video_name + \"_{:01d}.png\"\n",
    "    with sv.ImageSink(target_dir_path=IMAGE_DIR_PATH, image_name_pattern=image_name_pattern) as sink:\n",
    "        for image in sv.get_video_frames_generator(source_path=str(video_path), stride=FRAME_STRIDE):\n",
    "            sink.save_image(image=image)\n",
    "\n",
    "image_paths = sv.list_files_with_extensions(\n",
    "    directory=IMAGE_DIR_PATH,\n",
    "    extensions=[\"png\", \"jpg\", \"jpg\"])\n",
    "\n",
    "print('image count:', len(image_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaa8423",
   "metadata": {},
   "source": [
    "View sample of extracted frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e127c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import supervision as sv\n",
    "\n",
    "titles = [\n",
    "    image_path.stem\n",
    "    for image_path\n",
    "    in image_paths[:SAMPLE_SIZE]]\n",
    "images = [\n",
    "    cv2.imread(str(image_path))\n",
    "    for image_path\n",
    "    in image_paths[:SAMPLE_SIZE]]\n",
    "\n",
    "sv.plot_images_grid(images=images, titles=titles, grid_size=SAMPLE_GRID_SIZE, size=SAMPLE_PLOT_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ccccbb",
   "metadata": {},
   "source": [
    "Labeling initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75108a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autodistill.detection import CaptionOntology\n",
    "\n",
    "ontology=CaptionOntology({\n",
    "    \"person\": \"person\",\n",
    "    \"bag\": \"bag\",\n",
    "    \"cycle\": \"cycle\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a36d048",
   "metadata": {},
   "source": [
    "Annotation and Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87c8fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autodistill_grounded_sam import GroundedSAM\n",
    "\n",
    "base_model = GroundedSAM(ontology=ontology)\n",
    "dataset = base_model.label(\n",
    "    input_folder=IMAGE_DIR_PATH,\n",
    "    extension=\".png\",\n",
    "    output_folder=DATASET_DIR_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4324c1",
   "metadata": {},
   "source": [
    "Delete non-desired folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "folder_paths = [\n",
    "    \"Dataset/annotations\",\n",
    "    \"Dataset/images\",\n",
    "    \"Images\"\n",
    "]\n",
    "\n",
    "for folder in folder_paths:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)\n",
    "        print(f\"Deleted: {folder}\")\n",
    "    else:\n",
    "        print(f\"Not found: {folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec36453",
   "metadata": {},
   "source": [
    "Delete non-labeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb125c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def remove_empty_labels(base_path):\n",
    "    splits = [\"train\", \"valid\"]\n",
    "    for split in splits:\n",
    "        labels_dir = os.path.join(base_path, split, \"labels\")\n",
    "        images_dir = os.path.join(base_path, split, \"images\")\n",
    "\n",
    "        for label_file in os.listdir(labels_dir):\n",
    "            label_path = os.path.join(labels_dir, label_file)\n",
    "            # Check if label file is empty \n",
    "            if os.path.getsize(label_path) == 0:\n",
    "                image_file = os.path.splitext(label_file)[0] + \".jpg\"  \n",
    "                image_path_jpg = os.path.join(images_dir, image_file)\n",
    "                image_file_png = os.path.splitext(label_file)[0] + \".png\"\n",
    "                image_path_png = os.path.join(images_dir, image_file_png)\n",
    "\n",
    "                # Delete label file\n",
    "                os.remove(label_path)\n",
    "                print(f\"Deleted empty label: {label_path}\")\n",
    "\n",
    "                # Delete corresponding image (try jpg, then png)\n",
    "                if os.path.exists(image_path_jpg):\n",
    "                    os.remove(image_path_jpg)\n",
    "                    print(f\"Deleted corresponding image: {image_path_jpg}\")\n",
    "                elif os.path.exists(image_path_png):\n",
    "                    os.remove(image_path_png)\n",
    "                    print(f\"Deleted corresponding image: {image_path_png}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Corresponding image not found for label: {label_path}\")\n",
    "\n",
    "remove_empty_labels(\"Dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bccba2",
   "metadata": {},
   "source": [
    "Show sample for labeled train frames (Segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9308d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS_DIRECTORY_PATH = \"Dataset/train/labels\"\n",
    "IMAGES_DIRECTORY_PATH = \"Dataset/train/images\"\n",
    "DATA_YAML_PATH = \"Dataset/data.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "from pathlib import Path\n",
    "\n",
    "dataset = sv.DetectionDataset.from_yolo(\n",
    "    images_directory_path=IMAGES_DIRECTORY_PATH,\n",
    "    annotations_directory_path=ANNOTATIONS_DIRECTORY_PATH,\n",
    "    data_yaml_path=DATA_YAML_PATH)\n",
    "\n",
    "mask_annotator = sv.MaskAnnotator()\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "images = []\n",
    "image_names = []\n",
    "for i, (image_path, image, annotation) in enumerate(dataset):\n",
    "    if i == SAMPLE_SIZE:\n",
    "        break\n",
    "    annotated_image = image.copy()\n",
    "    annotated_image = mask_annotator.annotate(\n",
    "        scene=annotated_image, detections=annotation)\n",
    "    annotated_image = box_annotator.annotate(\n",
    "        scene=annotated_image, detections=annotation)\n",
    "    annotated_image = label_annotator.annotate(\n",
    "        scene=annotated_image, detections=annotation)\n",
    "\n",
    "    image_names.append(Path(image_path).name)\n",
    "    images.append(annotated_image)\n",
    "\n",
    "sv.plot_images_grid(\n",
    "    images=images,\n",
    "    titles=image_names,\n",
    "    grid_size=SAMPLE_GRID_SIZE,\n",
    "    size=SAMPLE_PLOT_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1983ee8",
   "metadata": {},
   "source": [
    "Split the dataset to Train, Valid, and Test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acfb23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def create_test_split(base_path, test_ratio=0.1):\n",
    "    train_images_dir = os.path.join(base_path, \"train\", \"images\")\n",
    "    train_labels_dir = os.path.join(base_path, \"train\", \"labels\")\n",
    "    test_images_dir = os.path.join(base_path, \"test\", \"images\")\n",
    "    test_labels_dir = os.path.join(base_path, \"test\", \"labels\")\n",
    "\n",
    "    os.makedirs(test_images_dir, exist_ok=True)\n",
    "    os.makedirs(test_labels_dir, exist_ok=True)\n",
    "\n",
    "    train_images = os.listdir(train_images_dir)\n",
    "    num_test = int(len(train_images) * test_ratio)\n",
    "\n",
    "    test_images = random.sample(train_images, num_test)\n",
    "\n",
    "    for img_name in test_images:\n",
    "        label_name = os.path.splitext(img_name)[0] + \".txt\"\n",
    "\n",
    "        # Source paths\n",
    "        src_img = os.path.join(train_images_dir, img_name)\n",
    "        src_lbl = os.path.join(train_labels_dir, label_name)\n",
    "\n",
    "        # Destination paths\n",
    "        dst_img = os.path.join(test_images_dir, img_name)\n",
    "        dst_lbl = os.path.join(test_labels_dir, label_name)\n",
    "\n",
    "        # Move image and label files\n",
    "        shutil.move(src_img, dst_img)\n",
    "        if os.path.exists(src_lbl):\n",
    "            shutil.move(src_lbl, dst_lbl)\n",
    "        else:\n",
    "            print(f\"Label file not found for image: {img_name}\")\n",
    "\n",
    "    print(f\"Created test split with {num_test} samples moved from train to test.\")\n",
    "\n",
    "create_test_split(\"Dataset\", test_ratio=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54a1d8c",
   "metadata": {},
   "source": [
    "Modify .yaml file by adding test folder path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf699850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "base_path = Path(\"Dataset\")\n",
    "\n",
    "# Load YAML file\n",
    "yaml_path = base_path / \"data.yaml\"\n",
    "with open(yaml_path, 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "test_path = (base_path / \"test\" / \"images\").resolve()\n",
    "test_path_str = str(test_path)\n",
    "dataset_index = test_path_str.find(\"Dataset\")\n",
    "if dataset_index != -1:\n",
    "    prefix = test_path_str[:dataset_index]\n",
    "    suffix = test_path_str[dataset_index:]\n",
    "    suffix = suffix.replace(\"\\\\\", \"/\")\n",
    "    test_path_str = prefix + suffix\n",
    "\n",
    "data['test'] = test_path_str\n",
    "\n",
    "with open(yaml_path, 'w') as file:\n",
    "    yaml.dump(data, file, default_flow_style=False)\n",
    "\n",
    "print(\"Added 'test' path with mixed separators to YAML file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a9f8f9",
   "metadata": {},
   "source": [
    "Convert labels to YOLO bounding box format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f090bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def polygon_to_bbox(coords):\n",
    "    xs = coords[0::2]\n",
    "    ys = coords[1::2]\n",
    "    x_min, x_max = min(xs), max(xs)\n",
    "    y_min, y_max = min(ys), max(ys)\n",
    "    x_center = (x_min + x_max) / 2\n",
    "    y_center = (y_min + y_max) / 2\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    return x_center, y_center, width, height\n",
    "\n",
    "def convert_labels_to_yolo_format(base_path):\n",
    "    label_dirs = [os.path.join(base_path, split, \"labels\") for split in [\"train\", \"valid\", \"test\"]]\n",
    "    for label_dir in label_dirs:\n",
    "        if not os.path.exists(label_dir):\n",
    "            print(f\"Label directory does not exist: {label_dir}\")\n",
    "            continue\n",
    "        \n",
    "        label_files = glob(os.path.join(label_dir, \"*.txt\"))\n",
    "        print(f\"Processing {len(label_files)} labels in {label_dir}\")\n",
    "\n",
    "        for lbl_file in label_files:\n",
    "            with open(lbl_file, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            new_lines = []\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 3 or len(parts) % 2 == 0:\n",
    "                    print(f\"Skipping malformed line in {lbl_file}: {line.strip()}\")\n",
    "                    continue\n",
    "                class_id = parts[0]\n",
    "                coords = list(map(float, parts[1:]))\n",
    "\n",
    "                # Convert polygon to bounding box\n",
    "                x_c, y_c, w, h = polygon_to_bbox(coords)\n",
    "                new_line = f\"{class_id} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\\n\"\n",
    "                new_lines.append(new_line)\n",
    "            \n",
    "            # Overwrite label file with YOLO bounding box format\n",
    "            with open(lbl_file, \"w\") as f:\n",
    "                f.writelines(new_lines)\n",
    "\n",
    "    print(\"Conversion to YOLO bounding boxes completed.\")\n",
    "\n",
    "convert_labels_to_yolo_format(\"Dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4715767a",
   "metadata": {},
   "source": [
    "Show sample for labeled frames (YOLO Bounding Box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a8d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "from pathlib import Path\n",
    "\n",
    "dataset = sv.DetectionDataset.from_yolo(\n",
    "    images_directory_path=IMAGES_DIRECTORY_PATH,\n",
    "    annotations_directory_path=ANNOTATIONS_DIRECTORY_PATH,\n",
    "    data_yaml_path=DATA_YAML_PATH)\n",
    "\n",
    "mask_annotator = sv.MaskAnnotator()\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "images = []\n",
    "image_names = []\n",
    "for i, (image_path, image, annotation) in enumerate(dataset):\n",
    "    if i == SAMPLE_SIZE:\n",
    "        break\n",
    "    annotated_image = image.copy()\n",
    "    annotated_image = mask_annotator.annotate(\n",
    "        scene=annotated_image, detections=annotation)\n",
    "    annotated_image = box_annotator.annotate(\n",
    "        scene=annotated_image, detections=annotation)\n",
    "    annotated_image = label_annotator.annotate(\n",
    "        scene=annotated_image, detections=annotation)\n",
    "\n",
    "    image_names.append(Path(image_path).name)\n",
    "    images.append(annotated_image)\n",
    "\n",
    "sv.plot_images_grid(\n",
    "    images=images,\n",
    "    titles=image_names,\n",
    "    grid_size=SAMPLE_GRID_SIZE,\n",
    "    size=SAMPLE_PLOT_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f491642a",
   "metadata": {},
   "source": [
    "Save sample for labeled frames (YOLO Bounding Box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430f21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "def draw_yolo_boxes_on_image(image_path, label_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Failed to read image: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    h, w, _ = img.shape\n",
    "    if not os.path.exists(label_path):\n",
    "        return img  \n",
    "\n",
    "    with open(label_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            class_id, x_c, y_c, bw, bh = map(float, parts)\n",
    "            x_center, y_center = int(x_c * w), int(y_c * h)\n",
    "            box_w, box_h = int(bw * w), int(bh * h)\n",
    "            x1 = int(x_center - box_w / 2)\n",
    "            y1 = int(y_center - box_h / 2)\n",
    "            x2 = int(x_center + box_w / 2)\n",
    "            y2 = int(y_center + box_h / 2)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(img, str(int(class_id)), (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    return img\n",
    "\n",
    "def save_random_bbox_previews(base_path, output_dir=\"preview_sample\", count=10):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    all_img_paths = []\n",
    "    for split in [\"train\", \"valid\", \"test\"]:\n",
    "        img_dir = os.path.join(base_path, split, \"images\")\n",
    "        if os.path.exists(img_dir):\n",
    "            all_img_paths.extend(glob(os.path.join(img_dir, \"*.jpg\")))\n",
    "\n",
    "    if len(all_img_paths) == 0:\n",
    "        print(\"No images found.\")\n",
    "        return\n",
    "\n",
    "    sample_imgs = random.sample(all_img_paths, min(count, len(all_img_paths)))\n",
    "\n",
    "    for i, img_path in enumerate(sample_imgs):\n",
    "        label_path = img_path.replace(\"images\", \"labels\").replace(\".jpg\", \".txt\")\n",
    "        preview_img = draw_yolo_boxes_on_image(img_path, label_path)\n",
    "        if preview_img is not None:\n",
    "            output_path = os.path.join(output_dir, f\"preview_{i}.jpg\")\n",
    "            cv2.imwrite(output_path, preview_img)\n",
    "\n",
    "    print(f\"Saved {len(sample_imgs)} preview images with bounding boxes in: {output_dir}\")\n",
    "\n",
    "save_random_bbox_previews(\"Dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5b2354",
   "metadata": {},
   "source": [
    "Fine-tune a YOLO model using the annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a60f0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Load a pretained YOLO model (yolov8n.pt - yolov8s.pt - yolov8m.pt - ...) as needed\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Train the model with save_period set to 50\n",
    "model.train(\n",
    "    data=\"Dataset\\\\data.yaml\",      # Path to your dataset configuration file\n",
    "    epochs=50,                      # Total number of training epochs\n",
    "    imgsz=360,                      # Image size\n",
    "    batch=16,                       # Batch size\n",
    "    name=\"Trained_Model\",           # Name for the training run\n",
    "    workers=0\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
